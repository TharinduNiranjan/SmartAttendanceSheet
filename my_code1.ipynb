{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " enter user id end press <return> ==>   8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Initializing face capture. Look the camera and wait ...\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n",
      "\n",
      " [INFO] Training faces. It will take a few seconds. Wait ...\n",
      "\n",
      " [INFO] 8 faces trained. Exiting Program\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2,os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import sqlite3\n",
    "# multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "cap.set(3,640) # set Width\n",
    "cap.set(4,480) # set Height\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]  \n",
    "    cv2.imshow('video',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "face_cascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "eye_cascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "path='C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"C:/Users/DELL/Desktop/Face_Recognition/data/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "        \n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 200: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = face_detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\");\n",
    "\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['None','Tharindu','Akka','Amanda','Ayya','dinga','nazier','supun','Malintha'] \n",
    "# Initialize and start realtime video capture\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            print(id)\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"test\")\n",
    "img_counter = 0\n",
    "path = 'C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\dataset'\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    cv2.imshow(\"test\", frame)\n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        img_name = \"opencv_frame_{}.jpg\".format(img_counter)\n",
    "        cv2.imwrite(os.path.join(path , img_name), frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "cap = cv2.VideoCapture(0)\n",
    "count=0\n",
    "face_id='1'\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\trainer\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('img', img)\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['opencv_frame_0.jpg', 'opencv_frame_0.png', 'opencv_frame_1.png', 'opencv_frame_2.png', 'opencv_frame_3.png', 'opencv_frame_4.png']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'subject_images_names' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ceba978a259b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mprepare_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_folder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-ceba978a259b>\u001b[0m in \u001b[0;36mprepare_training_data\u001b[1;34m(data_folder_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0msubject_images_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubject_images_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'subject_images_names' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import cv2,os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#this function will read all persons' training images, detect face from each image\n",
    "#and will return two lists of exactly same size, one list \n",
    "#of faces and another list of labels for each face\n",
    "data_folder_path='C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\dataset'\n",
    "def prepare_training_data(data_folder_path):\n",
    "\n",
    "    dirs= os.listdir(data_folder_path);\n",
    "    faces = []\n",
    "    labels = []\n",
    "    print(dirs)\n",
    "    for dir_name in dirs:\n",
    "        if not dir_name.startswith(\"s\"):\n",
    "            continue;\n",
    "        label = int(dir_name.replace(\"s\", \"\"))\n",
    " \n",
    "\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    " \n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "    for image_name in subject_images_names:\n",
    " \n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "\n",
    "    image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    cv2.imshow(\"Training on image...\", image)\n",
    "    cv2.waitKey(100)\n",
    "\n",
    "    face, rect = detect_face(image)\n",
    "\n",
    "    if face is not None:\n",
    "\n",
    "        faces.append(face)\n",
    "\n",
    "        labels.append(label)\n",
    " \n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.waitKey(1)\n",
    "        cv2.destroyAllWindows()\n",
    " \n",
    "    return faces, labels\n",
    "prepare_training_data(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video width\n",
    "cam.set(4, 480) # set video height\n",
    "path='C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "# For each person, enter one numeric face id\n",
    "face_id = 1\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cam.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\Data/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >=100: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = face_detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "# Path for face image database\n",
    "path = 'C:\\\\Users\\DELL\\Desktop\\Face_Recognition\\Data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\");\n",
    "# function to get the images and label data\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "font = cv2.FONT_HERSpython andHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 1\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['None','Tharindu'] \n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "        minSize = (int(minW), int(minH)),\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      " enter user id end press <return> ==>   1\n"
     ]
    }
   ],
   "source": [
    "face_id = input('\\n enter user id end press <return> ==>  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2,os\n",
    "from PIL import Image\n",
    "import glob\n",
    "images = [cv2.imread(file) for file in glob.glob(\"C:/Users/DELL/Desktop/Face_Recognition/data/*.jpg\")]\n",
    "try:\n",
    "    \n",
    "    os.remove(\"C:/Users/DELL/Desktop/Face_Recognition/data/*.jpg\")\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces detected=18\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "frame=cv.imread(\"F:/Knuckles/DCIM/101D7100/DSC_5913.JPG\")\n",
    "\n",
    "faceCascade=cv.CascadeClassifier(\"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\")\n",
    "gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "face=faceCascade.detectMultiScale(gray,scaleFactor=1.15,minNeighbors=5)\n",
    "print('faces detected='+str(len(face)))\n",
    "for (x,y,w,h) in face:\n",
    "    cv.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),8)\n",
    "    roi_gray=gray[y:y+h,x:x+w]\n",
    "    roi_color=frame[y:y+h,x:x+w]\n",
    "frame=cv.resize(frame,(600,400))\n",
    "cv.imshow('frame',frame)\n",
    "cv.waitKey(0) \n",
    "cv.destroyAllWindows()\n",
    "path='destination path'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "def getImagesAndLabels(path):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2,os\n",
    "from PIL import Image\n",
    "import glob\n",
    "# multiple cascades: https://github.com/Itseez/opencv/tree/master/data/haarcascades\n",
    "cap = cv2.VideoCapture(0)\n",
    "faceCascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "cap.set(3,640) # set Width\n",
    "cap.set(4,480) # set Height\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5)    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]  \n",
    "    cv2.imshow('video',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "face_cascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "eye_cascade = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_eye.xml')\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_id = input('\\n enter user id end press <return> ==>  ')\n",
    "print(\"\\n [INFO] Initializing face capture. Look the camera and wait ...\")\n",
    "# Initialize individual sampling face count\n",
    "count = 0\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"C:/Users/DELL/Desktop/Face_Recognition/data/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cap = cv2.VideoCapture(0)\n",
    "path='C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1) # flip video image vertically\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)     \n",
    "        count += 1\n",
    "        # Save the captured image into the datasets folder\n",
    "        cv2.imwrite(\"C:/Users/DELL/Desktop/Face_Recognition/dataset/User.\" + str(face_id) + '.' + str(count) + \".jpg\", gray[y:y+h,x:x+w])\n",
    "        cv2.imshow('image', img)\n",
    "        \n",
    "    k = cv2.waitKey(100) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif count >= 30: # Take 30 face sample and stop video\n",
    "         break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "def getImagesAndLabels(path):\n",
    "    imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n",
    "    faceSamples=[]\n",
    "    ids = []\n",
    "    for imagePath in imagePaths:\n",
    "        PIL_img = Image.open(imagePath).convert('L') # convert it to grayscale\n",
    "        img_numpy = np.array(PIL_img,'uint8')\n",
    "        id = int(os.path.split(imagePath)[-1].split(\".\")[1])\n",
    "        faces = face_detector.detectMultiScale(img_numpy)\n",
    "        for (x,y,w,h) in faces:\n",
    "            faceSamples.append(img_numpy[y:y+h,x:x+w])\n",
    "            ids.append(id)\n",
    "    return faceSamples,ids\n",
    "print (\"\\n [INFO] Training faces. It will take a few seconds. Wait ...\")\n",
    "faces,ids = getImagesAndLabels(path)\n",
    "recognizer.train(faces, np.array(ids))\n",
    "# Save the model into trainer/trainer.yml\n",
    "recognizer.write('trainer/trainer.yml') # recognizer.save() worked on Mac, but not on Pi\n",
    "# Print the numer of faces trained and end program\n",
    "print(\"\\n [INFO] {0} faces trained. Exiting Program\".format(len(np.unique(ids))))\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/dataset'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\");\n",
    "\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['None','Malintha','Tharindu'] \n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "51.23906730019511\n",
      "53.30124749565478\n",
      "52.106300873340054\n",
      "52.32945567941594\n",
      "54.463742569379676\n",
      "51.968295595753034\n",
      "50.57858762138513\n",
      "51.505535146652704\n",
      "51.90428009012961\n",
      "51.90428009012961\n",
      "51.360892764566195\n",
      "52.58794919427617\n",
      "52.606223455500384\n",
      "52.782649567848594\n",
      "51.88246809448143\n",
      "51.73812127363669\n",
      "51.73812127363669\n",
      "51.99452570777269\n",
      "51.9914813522932\n",
      "52.00864531210665\n",
      "52.331676775082244\n",
      "53.99449005866479\n",
      "52.216555230656695\n",
      "51.73968533693562\n",
      "52.841872394865746\n",
      "51.707643396667386\n",
      "51.707643396667386\n",
      "53.519664108423626\n",
      "51.61160444390224\n",
      "51.88062252385032\n",
      "53.41084949018458\n",
      "50.398988979716705\n",
      "50.01687848083466\n",
      "52.008259461747855\n",
      "48.537051234775234\n",
      "51.618825996480396\n",
      "50.85638069841177\n",
      "50.85638069841177\n",
      "51.695130554331435\n",
      "50.85557698158799\n",
      "48.574070977658856\n",
      "48.4322959260892\n",
      "47.97966884909688\n",
      "48.01277664892164\n",
      "48.12963347143111\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2,os\n",
    "from PIL import Image\n",
    "import glob\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "face_detector = cv2.CascadeClassifier('F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['None','Malintha','Tharindu'] \n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "print(len(names))\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "       )\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        print(confidence)\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        if (confidence < 100):\n",
    "            id = names[id]\n",
    "            \n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            \n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "    \n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e92415389837>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmisc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "<class 'str'>\n",
      "\n",
      " [INFO] Exiting Program and cleanup stuff\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os \n",
    "import sqlite3\n",
    "from datetime import date\n",
    "\n",
    "path = 'C:/Users/DELL/Desktop/Face_Recognition/data'\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "detector = cv2.CascadeClassifier(\"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\");\n",
    "\n",
    "recognizer.read('trainer/trainer.yml')\n",
    "cascadePath = \"F:\\Anaconda\\Library\\etc\\haarcascades\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath);\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#iniciate id counter\n",
    "id = 0\n",
    "# names related to ids: example ==> Marcelo: id=1,  etc\n",
    "names = ['None','Tharindu','Akka','Amanda','Ayya','dinga','nazier','supun','Malintha'] \n",
    "# Initialize and start realtime video capture\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3, 640) # set video widht\n",
    "cam.set(4, 480) # set video height\n",
    "# Define min window size to be recognized as a face\n",
    "minW = 0.1*cam.get(3)\n",
    "minH = 0.1*cam.get(4)\n",
    "\n",
    "while True:\n",
    "    ret, img =cam.read()\n",
    "    img = cv2.flip(img, 1) # Flip vertically\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = faceCascade.detectMultiScale( \n",
    "        gray,\n",
    "        scaleFactor = 1.2,\n",
    "        minNeighbors = 5,\n",
    "       )\n",
    "    \n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confidence = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "        # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "        #print(id)\n",
    "        if (confidence < 100):\n",
    "            #print(id)\n",
    "            id = names[id]\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        else:\n",
    "            id = \"unknown\"\n",
    "            confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "        \n",
    "        cv2.putText(img, str(id), (x+5,y-5), font, 1, (255,255,255), 2)\n",
    "        cv2.putText(img, str(confidence), (x+5,y+h-5), font, 1, (255,255,0), 1)  \n",
    "    #print(id)\n",
    "    #print(names.index(id))\n",
    "\n",
    "    cv2.imshow('camera',img) \n",
    "    k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video\n",
    "    if k == 27:\n",
    "        break\n",
    "# Do a bit of cleanup\n",
    "n=names.index(id)\n",
    "print(n)\n",
    "print(type(id))\n",
    "conn=sqlite3.connect(\"C:/Users/DELL/Desktop/Face_Recognition/newdatabase.db\")\n",
    "c=conn.cursor()\n",
    "today = str(date.today())\n",
    "def create():\n",
    "    c.execute(\"CREATE TABLE IF NOT EXISTS stufftopull(id INT,names STRING)\")\n",
    "def data():\n",
    "    c.execute(\"INSERT INTO stufftopull(id,names) values(:id,:names)\",{'id':n,'names':id})\n",
    "    c.execute(\"INSERT INTO attendance(id,date) values(:id,:date)\",{'id':n,'date':today})\n",
    "    conn.commit()\n",
    "    c.close()\n",
    "    conn.close()\n",
    "print(\"\\n [INFO] Exiting Program and cleanup stuff\")\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "create()\n",
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
